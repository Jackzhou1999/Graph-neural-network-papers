# Learning Graph Convolutional Network for Skeleton-Based Human Action Recognition by Neural Searching
* **Author**:Wei Peng, Xiaopeng Hong, Haoyu Chen, Guoying Zhao
* **Abstract**:Human action recognition from skeleton data, fuelled by the Graph Convolutional Network (GCN) with its powerful capability of modeling non-Euclidean data, has attracted lots of attention. However, many existing GCNs provide a pre-defined graph structure and share it through the entire network, which can loss implicit joint correlations especially for the higherlevel features. Besides, the mainstream spectral GCN is approximated by one-order hop such that higher-order connections are not well involved. All of these require huge efforts to design a better GCN architecture. To address these problems, we turn to Neural Architecture Search (NAS) and propose the first automatically designed GCN for this task. Specifically, we explore the spatial-temporal correlations between nodes and build a search space with multiple dynamic graph modules. Besides, we introduce multiple-hop modules and expect to break the limitation of representational capacity caused by one-order approximation. Moreover, a corresponding sampling- and memory-efficient evolution strategy is proposed to search in this space. The resulted architecture proves the effectiveness of the higher-order approximation and the layer-wise dynamic graph modules. To evaluate the performance of the searched model, we conduct extensive experiments on two very large scale skeleton-based action recognition datasets. The results show that our model gets the stateof-the-art results in term of given metrics.
* **Summary**:In this paper, we propose to build graph convolutional network for skeleton-based action recognition with NAS. To enrich the NAS search space, firstly, three dynamic graph generating modules are constructed on the basis of various spatial-temporal correlations of nodes. Secondly, modules with higher-order connections are introduced to enlarge the receptive field of GCN convolution. Besides, we devise a novel search strategy by combining cross-entropy evolution strategy with importance-mixing (CEIM), which is both sampling- and memory-efficient. Based on the proposed NAS method, we explore the optimal GCN architecture in this space for skeleton action recognition. The searched model proves the effectiveness of our function modules. Comprehensive experiments on two very large scale datasets show its overwhelming performance when compared to the state-of-the-art approaches.
* **Keywords**:Human Action Recognition, GCN
* **Code**:https://github.com/xiaoiker/GCN-NAS
* **Dataset**:NTU RGB+D, Kinetics-Skeleton