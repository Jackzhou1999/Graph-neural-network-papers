# Part-Level Graph Convolutional Network for Skeleton-Based Action Recognition
* **Author**:Linjiang Huang, Yan Huang, Wanli Ouyang, Liang Wang
* **Abstract**:Recently, graph convolutional networks have achieved remarkable performance for skeleton-based action recognition. In this work, we identify a problem posed by the GCNs for skeleton-based action recognition, namely part-level action modeling. To address this problem, a novel Part-Level Graph Convolutional Network (PL-GCN) is proposed to capture part-level information of skeletons. Different from previous methods, the partition of body parts is learnable rather than manually defined. We propose two part-level blocks, namely Part Relation block (PR block) and Part Attention block (PA block), which are achieved by two differentiable operations, namely graph pooling operation and graph unpooling operation. The PR block aims at learning high-level relations between body parts while the PA block aims at highlighting the important body parts in the action. Integrating the original GCN with the two blocks, the PL-GCN can learn both part-level and joint-level information of the action. Extensive experiments on two benchmark datasets show the state-ofthe-art performance on skeleton-based action recognition and demonstrate the effectiveness of the proposed method.
* **Summary**:In this paper, we have proposed a novel Part-Level Graph Convolutional Network (PL-GCN) for skeleton-based action recognition. The construction of PL-GCN is mainly based on two blocks, i.e., Part Relation block (PR block) and Part Attention block (PA block). The PR block aims at learning part-level relations while the PA block aims at highlighting important body parts. We have evaluated our PL-GCN on two benchmark datasets and achieved state-of-the-art performance. In the future, we plan to further improve our method for automatically learning the number of body parts and focus more on modeling temporal dynamics of actions.
* **Keywords**:PL-GCN
* **Code**:
* **Dataset**:NTU RGB+D,SYSU