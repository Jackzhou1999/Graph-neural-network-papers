# Tensor Graph Convolutional Networks for Text Classification
* **Author**:Xien Liu, Xinxin You, Xiao Zhang, Ji Wu, Ping Lv
* **Abstract**:Compared to sequential learning models, graph-based neural networks exhibit some excellent properties, such as ability capturing global information. In this paper, we investigate graph-based neural networks for text classification problem. A new framework TensorGCN (tensor graph convolutional networks), is presented for this task. A text graph tensor is firstly constructed to describe semantic, syntactic, and sequential contextual information. Then, two kinds of propagation learning perform on the text graph tensor. The first is intra-graph propagation used for aggregating information from neighborhood nodes in a single graph. The second is inter-graph propagation used for harmonizing heterogeneous information between graphs. Extensive experiments are conducted on benchmark datasets, and the results illustrate the effectiveness of our proposed framework. Our proposed TensorGCN presents an effective way to harmonize and integrate heterogeneous information from different kinds of graphs.
* **Summary**:In this study, we propose a text graph tensor to capture features from semantic, syntactic, and sequential contextual information. Experimental results illustrate that these different context constraints are complementary and very important for text representation learning. Furthermore, we generalize the graph convolutional networks into a tensor version TensorGCN which can effectively harmonize and integrate heterogeneous information from multi-graphs by the intragraph and inter-graph propagation simultaneously learning strategy.
* **Keywords**:TensorGCN
* **Code**:https://github.com/xienliu/tensor-gcn-text-classification-tensorflow
* **Dataset**:20-Newsgroups,Ohsumed, R52 Reuters,R8 Reuters,Movie Review dataset