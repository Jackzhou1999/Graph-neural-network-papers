# Zero-Shot Sketch-Based Image Retrieval via Graph Convolution Network
* **Author**:Zhaolong Zhang, Yuejie Zhang, Rui Feng, Tao Zhang, Weiguo Fan
* **Abstract**:Zero-Shot Sketch-based Image Retrieval (ZS-SBIR) has been proposed recently, putting the traditional Sketch-based Image Retrieval (SBIR) under the setting of zero-shot learning. Dealing with both the challenges in SBIR and zero-shot learning makes it become a more difficult task. Previous works mainly focus on utilizing one kind of information, i.e., the visual information or the semantic information. In this paper, we propose a SketchGCN model utilizing the graph convolution network, which simultaneously considers both the visual information and the semantic information. Thus, our model can effectively narrow the domain gap and transfer the knowledge. Furthermore, we generate the semantic information from the visual information using a Conditional Variational Autoencoder rather than only map them back from the visual space to the semantic space, which enhances the generalization ability of our model. Besides, feature loss, classification loss, and semantic loss are introduced to optimize our proposed SketchGCN model. Our model gets a good performance on the challenging Sketchy and TU-Berlin datasets.
* **Summary**:In this paper, we propose the SketchGCN model for the ZSSBIR task, where we combine a GCN model and a CVAE model successively. The ability to handle relations of GCN helps us to deal with the similarities between sketches and images. Our model can leverage both the visual information and the semantic information effectively which benefits from the method of computing the adjacency matrix. The CVAE helps our model to gain the generalization ability to infer the unseen categories. In future work, we will consider exploring a more effective way to model the graph structure in the ZS-SBIR task.
* **Keywords**:Zero-Shot Sketch-Based Image Retrieval
* **Code**:
* **Dataset**:Sketchy,TU-Berlin datasets