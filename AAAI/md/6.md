# Fast and Deep Graph Neural Networks
* **Author**:Claudio Gallicchio,Alessio Micheli
* **Abstract**:We address the efficiency issue for the construction of a deep graph neural network (GNN). The approach exploits the idea of representing each input graph as a fixed point of a dynamical system (implemented through a recurrent neural network), and leverages a deep architectural organization of the recurrent units. Efficiency is gained by many aspects, including the use of small and very sparse networks, where the weights of the recurrent units are left untrained under the stability condition introduced in this work. This can be viewed as a way to study the intrinsic power of the architecture of a deep GNN, and also to provide insights for the set-up of more complex fully-trained models. Through experimental results, we show that even without training of the recurrent connections, the architecture of small deep GNN is surprisingly able to achieve or improve the state-of-the-art performance on a significant set of tasks in the field of graphs classification.
* **Summary**:We have introduced FDGNN, a novel NN model for fast learning in graph domains. The proposed approach showed that it is possible to combine the advantages of a deep architectural construction of GNN (in its ability to effectively process structured data in the form of general graphs), with the extreme efficiency of randomized NN, and in particular RC, methodologies. The randomized implementation allows us to implement untrained - but stable - graph embedding layers, while through the deep architecture the model is able to build a progressively more effective representation of the input graphs. Despite the simplicity of the setup and the fast computation allowed by the model, the empirical accuracy of FDGNN results to be very competitive with a large number of state-of-the-art CNN models and kernel methods for graphs. Further possible analysis on the expressive power of FDGNN can be related to the study of Markovian-based organization of graph embedding spaces.
* **Keywords**:Deep GNN
* **Code**:
* **Dataset**:MUTAG,PTC,COX2,PROTEINS,NCI1,IMDB-b,IMDB-m,REDDIT,COLLAB