# Aligned Dual Channel Graph Convolutional Network for Visual Question Answering
* **Author**: Qingbao Huang, Jielong Wei, Yi Cai1, Changmeng Zheng, Junying Chen, Ho-fung Leung, Qing Li
* **Abstract**:Visual question answering aims to answer the natural language question about a given image. Existing graph-based methods only focus on the relations between objects in an image and neglect the importance of the syntactic dependency relations between words in a question. To simultaneously capture the relations between objects in an image and the syntactic dependency relations between words in a question, we propose a novel dual channel graph convolutional network (DC-GCN) for better combining visual and textual advantages. The DC-GCN model consists of three parts: an I-GCN module to capture the relations between objects in an image, a Q-GCN module to capture the syntactic dependency relations between words in a question, and an attention alignment module to align image representations and question representations. Experimental results show that our model achieves comparable performance with the state-of-theart approaches.
* **Summary**:In this paper, we propose a dual channel graph convolutional network to explore the relations between objects in an image and the syntactic dependency relations between words in a question. Furthermore, we explicitly construct the relations between words by dependency tree and align the image and question representations by an attention alignment module to reduce the gaps between vision and language. Extensive experiments on the VQA-v2 and VQA-CP-v2 datasets demonstrate that our model achieves comparable performance with the stateof-the-art approaches. We will explore more complicated object relation modeling in future work.
* **Keywords**:DC-GCN
* **Code**:
* **Dataset**:VQA-v2, VQA-CP-v2