# Every Document Owns Its Structure Inductive Text Classification via Graph Neural Networks
* **Author**: Yufeng Zhang, Xueli Yu, Zeyu Cui, Shu Wu, Zhongzhen Wen, Liang Wang
* **Abstract**:Text classification is fundamental in natural language processing (NLP), and Graph Neural Networks (GNN) are recently applied in this task. However, the existing graph-based works can neither capture the contextual word relationships within each document nor fulfil the inductive learning of new words. In this work, to overcome such problems, we propose TextING1 for inductive text classification via GNN. We first build individual graphs for each document and then use GNN to learn the finegrained word representations based on their local structures, which can also effectively produce embeddings for unseen words in the new document. Finally, the word nodes are incorporated as the document embedding. Extensive experiments on four benchmark datasets show that our method outperforms state-of-theart text classification methods.
* **Summary**:We proposed a novel graph-based method for inductive text classification, where each text owns its structural graph and text level word interactions can be learned. Experiments proved the effectiveness of our approach in modelling local word-word relations and word significances in the text.
* **Keywords**:Inductive Text Classification
* **Code**:https://github.com/CRIPAC-DIG/TextING
* **Dataset**:  MR,  R8, R52, Ohsumed