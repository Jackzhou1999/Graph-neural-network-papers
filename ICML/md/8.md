# Learning Algebraic Multigrid Using Graph Neural Networks 
* **Author**: Ilay Luz , Meirav Galun , Haggai Maron , Ronen Basri , Irad Yavneh
* **Abstract**:Effcient numerical solvers for sparse linear systems are crucial in science and engineering. One of the fastest methods for solving largescale sparse linear systems is algebraic multigrid (AMG). The main challenge in the construction of AMG algorithms is the selection of the prolongation operatorâ€”a problem-dependent sparse matrix which governs the multiscale hierarchy of the solver and is critical to its effciency. Over many years, numerous methods have been developed for this task, and yet there is no known single right answer except in very special cases. Here we propose a framework for learning AMG prolongation operators for linear systems with sparse symmetric positive (semi-) defnite matrices. We train a single graph neural network to learn a mapping from an entire class of such matrices to prolongation operators, using an effcient unsupervised loss function. Experiments on a broad class of problems demonstrate improved convergence rates compared to classical AMG, demonstrating the potential utility of neural networks for developing sparse system solvers.
* **Summary**:In this paper we propose a framework for learning Algebraic Multigrid (AMG) prolongation operators for linear systems which are defned directly on graphs, rather than on structured grids. We treat linear systems that can be expressed by sparse symmetric positive (semi-) defnite matrices. We formulate the problem as a learning task and train a single graph neural network, with an effcient messagepassing architecture, to learn a mapping from an entire class of such matrices to prolongation operators. We employ an effcient and unsupervised training on a limited class of block-circulant matrices. Our experiments indicate success, i.e, improved convergence rates compared to classical AMG, on a variety of problems. This includes graph Laplacian problems over a triangulated mesh, where the edge weights are drawn randomly from some distribution, diffusion partial differential equations discretized on 2D triangular meshes and spectral clustering problems. An interesting and important direction for future research is learning to select the coarse representatives as well as the sparsity pattern of the prolongation matrix.
* **Keywords**: AMG
* **Code**:https://github.com/ilayluz/learning-amg
* **Dataset**: